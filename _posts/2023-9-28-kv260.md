---
layout: post
title:  "Setting up the Xilinx KV260"
date:   2023-09-28 17:37:00 -1000
categories: xilinx kv260 edge_ai
---

# Xilinx KV260
The KV260 is a relatively recent (2021) Xilinx product based on the Zynq Ultrascale
family, chips with Cortex-A53 processors and a variable amount of logic elements.

That being said, the Kria SOMs and their ecosystem are a bit unique compared to Xilinx's
historical offerings for a few reasons.
* Premade Ubuntu LTS rootfs and Xilinx PPAs for additional software
* Premade FPGA firmware images with the DPU (that's their ML accelerator IP) embedded
* Basic GPU and video codecs present
* Unusually low price of ~$250 for the developer kit, for a similar feature set to
  the more expensive Ultrascale+ EV

Although it can be used like any other Xilinx product with Vivado, Petalinux, etc, and
probably could serve as a great platform for getting a decently sized FPGA cheaply, the
Kria modules definitely feel more geared towards software developers trying to deploy
ML vision models, or anyone more familiar with single board computers like the Pi.
I'm not sure if it really competes with the Tegra family in practice since its compute
throughput is much lower but it seems aimed at the same use case.

I bought a KV260 devkit when it released back in 2021 while thinking of all the interesting
projects I could use it for, but as things often do, it went unused.
Now that the Ryzen 7040 mobile chips with XDNA AI accelerators have come out, and AMD
has [published some sample code](https://github.com/amd/RyzenAI-cloud-to-client-demo), I've decided to dust off the Kria and try to make use of Vitis AI in anticipation of a Linux
port of the Ryzen AI SDK (plz AMD).

Anyway, to get started, pull up the [Kria docs](https://xilinx.github.io/kria-apps-docs/kv260/2022.1/build/html/index.html) in a tab, and read on.
The Xilinx atlassian wiki shows up a lot in search results but looks out of sync on some points,
so the linked site seems to be most up to date.

## Running the NLP smartcamera application
Here are the condensed instructions to get up and running. The info here is all available in
their official docs, but it's scattered across several pages on different sites.
* Flash the [KV260 ubuntu 22.04 image](https://ubuntu.com/download/amd) onto an SD card
* Login with User: ubuntu, Password: ubuntu. You'll be asked to change it.
* `sudo systemctl stop unattended-upgrades.service; sudo apt-get purge unattended-upgrades`
  * If you leave this service enabled, you might be waiting a long time.
* `systemctl restart systemd-resolved` b/c DNS didn't start for some reason.
* `sudo snap install xlnx-config --classic --channel=2.x`
* `sudo xlnx-config.sysinit`
  * [If you get an error flashing kernel, just try again apparently...](https://xilinx.github.io/kria-apps-docs/kr260/build/html/docs/kria_starterkit_linux_boot.html)
* `sudo apt install xlnx-firmware-kv260-nlp-smartvision`
  * AFAICT [this is the repo that package is built from](https://github.com/Xilinx/kria-apps-firmware/tree/main/k26-dfx/2rp)
* [Now following the instructions for the nlp-smartcamera...](https://xilinx.github.io/kria-apps-docs/kv260/2022.1/build/html/docs/nlp-smartvision/docs/app_deployment_nlp.html)
  * `sudo xmutil listapps`
  * `sudo xmutil unloadapp`
  * `sudo xmutil loadapp kv260-nlp-smartvision`
  * `sudo apt install docker.io` and `sudo usermod -aG docker ubuntu`
  * `docker pull xilinx/nlp-smartvision:2022.1` This container is >1GB.
  * ```
    docker run \
        --env="DISPLAY" \
        -h "xlnx-docker" \
        --env="XDG_SESSION_TYPE" \
        --net=host \
        --privileged \
        -v /tmp:/tmp \
        -v /dev:/dev \
        -v /sys:/sys \
        -v /etc/vart.conf:/etc/vart.conf \
        -v /lib/firmware/xilinx:/lib/firmware/xilinx \
        -v /run:/run \
        -it xilinx/nlp-smartvision:2022.1 bash
    ```
  * Finally, get a random jpg online with some everyday objects in it, copy it
    to one of the paths mounted in the container like `/tmp`and try:
    `nlp-smartvision --test /tmp/pic.jpg yolov2_voc_pruned_0_77` in the container!

The purpose of loading one of Xilinx's demo apps is to get the DPU, their ML accelerator
into the SoC's FPGA fabric. The DPU isn't tied to a single model, so it should be possible
to deploy our own CNNs to it with some effort.

The process of making a bitstream with the DPU inside is a whole nother problem that would
require installing the entire Vivado/Vitis tool suite, so it's nice that we can leverage
some of the prebuilt resources.

## Building stuff with the Kria docker images
I wasn't expecting docker to be their approved way of running apps, but I think it works out.
An advantage of Xilinx making everything possible in a container is the app can be built offline
easily by just pulling the container on a host with qemu-user-static and binfmt setup to run
aarch64 binaries. NVIDIA pushes users towards a similar flow on the Tegra platform, so maybe that's
just where the embedded AI stuff is going. That being said, containers are more of a convenience
here, the options needed to make it work throw out any semblance of isolation or security.

The demo is nice and all, but anyone following this post probably cares about making
a custom application. The most "software developer" friendly way of doing this seems to be
using the Xilinx Kria docker images, so let's start there and rebuild the nlp-smartvision app.
* First, I'm going to install `qemu-user-static` on my Ubuntu-based host machine. That
  combined with binfmt lets you run binaries from other architectures on your machine.
  Since the Kria modules have aarch64 CPUs, we need this to run the Kria containers.
* Now if I do `docker run -it --rm xilinx/kria-developer:latest`, I should end up in the
  container and be able to use basic utilities like `ls`.
* Inside the container, I'll clone the app's repo, https://github.com/Xilinx/nlp-smartvision,
  and do the usual cmake incantation. Thankfully this built without errors!

## Building the Vitis AI container
I'll add this step here too since it's just more busywork, but next I have to build the
Vitis AI container. The tools for quantizing (more on that later) and a distribution of
PyTorch is in here, which we'll need for producing our own model weights later. There are
some prebuilt Vitis AI containers on dockerhub, but if you've got an NVIDIA card you'll need
to build it yourself. Figures.

Since the version of Vitis AI in the repos is v2.5, I'll start by trying to build the container
from the v2.5 tag.
```
git clone https://github.com/Xilinx/Vitis-AI.git --branch v2.5
cd Vitis-AI/docker
bash docker_build_gpu.sh
```
And here's the first blocker. The base image used is no longer on docker hub. I changed it to
a newer CUDA 11.8 version with a similar image, nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu18.04,
but this _also_ fails to build, hanging indefinitely when trying to install the PyTorch
environment's packages. It looks conda can't find some of the Xilinx conda packages, perhaps
they're no longer hosted online or something, but at any rate I decided to pull the CPU-only
Vitis AI v2.5 container at this point, which _is_ on docker hub [here](https://hub.docker.com/r/xilinx/vitis-ai-cpu/tags).
Simply doing `docker pull xilinx/vitis-ai-cpu:2.5.0` will get you that image.

I would have liked if a newer version of Vitis AI was available for the Kria, but the Ubuntu PPA
that provides those packages is still on 2.5. I started making my own dockerfile to compile v3.5
of vitis-ai-runtime, vitis-ai-library, vvas-essentials, but it's still WIP.

## Useful links
* Kria Docker https://github.com/Xilinx/kria-docker
* Vitis AI v2.5 Docker image https://hub.docker.com/r/xilinx/vitis-ai-cpu/tags
* NLP smartvision app https://github.com/Xilinx/nlp-smartvision
* Kria prebuilt firmware https://github.com/Xilinx/kria-apps-firmware/tree/main/k26-dfx/2rp
